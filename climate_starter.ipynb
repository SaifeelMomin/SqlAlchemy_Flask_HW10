{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext blackcellmagic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n",
    "inspector = inspect(engine)\n",
    "mCols = inspector.get_columns(\"measurement\")\n",
    "sCols = inspector.get_columns(\"station\")\n",
    "\n",
    "\n",
    "def colnames(col_list):\n",
    "    for c in col_list:\n",
    "        print(c[\"name\"], c[\"type\"])\n",
    "\n",
    "\n",
    "print(\"Measurement columns:\")\n",
    "colnames(mCols)\n",
    "print(\"Stations columns:\")\n",
    "colnames(sCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis\n",
    "\n",
    "* Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "\n",
    "* Calculate the date 1 year ago from the last data point in the database\n",
    "\n",
    "* Perform a query to retrieve the data and precipitation scores\n",
    "\n",
    "* Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "\n",
    "# Sort the dataframe by date\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "#### Calculate the date 1 year ago from the last data point in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_uniq = []\n",
    "for value in session.query(Measurement.date).distinct():\n",
    "    dates_uniq.append(value.date)\n",
    "end_date = max(dates_uniq)\n",
    "start_date = str(dmax - dt.timedelta(365))[:10]\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query to retrieve the data and precipitation scores\n",
    "df_prcp_data = []\n",
    "df_prcp_sum = []\n",
    "\n",
    "q = (\n",
    "    session.query(Measurement.date, Measurement.prcp)\n",
    "    .filter(Measurement.date >= start_date)\n",
    "    .all()\n",
    ")\n",
    "for record in q:\n",
    "    df_prcp_data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "df_prcp = pd.DataFrame(df_prcp_data).set_index(\"date\")\n",
    "df_prcp = df_prcp.dropna(axis=0, how=\"any\")\n",
    "df_prcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ticks(y, m, day, months):\n",
    "    trip_data = [f\"{y}-0{m}-{day}\"]\n",
    "    start_month = dt.datetime(y, m, day)\n",
    "    for i in range(int(months / 2)):\n",
    "        next_month = start_month + rd(months=+2)\n",
    "        # next_month = next_month.strftime('%Y-%m-%d')\n",
    "        # month_data = calc_temps(start_month, next_month)\n",
    "        trip_data.append(next_month.strftime(\"%Y-%m-%d\"))\n",
    "        start_month = next_month\n",
    "    return trip_data\n",
    "\n",
    "\n",
    "x_ticks = plot_ticks(2016, 8, 23, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-08-23',\n",
       " '2016-10-23',\n",
       " '2016-12-23',\n",
       " '2017-02-23',\n",
       " '2017-04-23',\n",
       " '2017-06-23',\n",
       " '2017-08-23']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_prcp.index, y=df_prcp[\"prcp\"])\n",
    "plt.xticks(ticks=x_ticks, rotation=90)\n",
    "plt.ylabel(\"Precipitation\")\n",
    "plt.title(\"Last 12 months of Precipitation data\")\n",
    "plt.savefig(\"plot_prcp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Pandas to print the summary statistics for the precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_dict = {\n",
    "    \"count\": df_prcp.shape[0],\n",
    "    \"mean\": df_prcp[\"prcp\"].mean(),\n",
    "    \"std\": df_prcp[\"prcp\"].std(),\n",
    "    \"min\": df_prcp[\"prcp\"].min(),\n",
    "    \"25%\": df_prcp[\"prcp\"].quantile(0.25),\n",
    "    \"50%\": df_prcp[\"prcp\"].quantile(0.50),\n",
    "    \"75%\": df_prcp[\"prcp\"].quantile(0.75),\n",
    "    \"max\": df_prcp[\"prcp\"].max(),\n",
    "}\n",
    "df_summ = pd.DataFrame(summ_dict, index=(\"precipitation\", 1))\n",
    "df_summ = df_summ.drop([1]).T\n",
    "df_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design a query to show how many stations are available in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = session.query(Station.station).distinct().all()\n",
    "print(len(stations))\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the stations and observation counts in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data1 = []\n",
    "df_data1_sums = []\n",
    "query = (\n",
    "    session.query(Measurement, func.count(Measurement.station))\n",
    "    .group_by(Measurement.station)\n",
    "    .all()\n",
    ")\n",
    "for record in query:\n",
    "    df_data1.append(record[0].__dict__)\n",
    "    df_data1_sums.append(record[1])\n",
    "\n",
    "df_stations = pd.DataFrame(df_data1).set_index(\"station\")\n",
    "df_stations[\"counts\"] = df_data1_sums\n",
    "df_stations = df_stations.sort_values(\"counts\", ascending=False,)\n",
    "df_stations = pd.DataFrame(df_stations[\"counts\"])\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which station has the highest number of observations\n",
    "##### USC00519281    Observations: 2772"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the station id from the previous query, calculate the lowest temperature recorded, highest temperature recorded, and average temperature most active station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (\n",
    "    session.query(\n",
    "        func.min(Measurement.tobs),\n",
    "        func.avg(Measurement.tobs),\n",
    "        func.max(Measurement.tobs),\n",
    "    )\n",
    "    .filter(Measurement.station == \"USC00519281\")\n",
    "    .all()\n",
    ")\n",
    "print(\"Station: USC00519281\", \"min:\", q[0][0], \"max:\", q[0][1], \"avg:\", q[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the station with the highest number of temperature observations.\n",
    "##### USC00519281    Observations: 2772\n",
    "#### Query the last 12 months of temperature observation data for this station and plot the results as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Active Station\n",
    "# Measurement.station == USC00519281\n",
    "df_tobs_data = []\n",
    "q = session.query(Measurement.tobs).filter(Measurement.station == \"USC00519281\").all()\n",
    "for record in q:\n",
    "    df_tobs_data.append(record[0])\n",
    "\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.title(\"Last 12 Months of Temperature Data (USC00519281)\")\n",
    "fig = plt.hist(x=df_tobs_data, bins=12)\n",
    "plt.savefig(\"plot_tobs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' and return the minimum, average, and maximum temperatures for that range of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax for your trip using the previous year's data for those same dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_start = \"2016-04-01\"\n",
    "trip_end = \"2016-04-11\"\n",
    "trip_early_start = str(\n",
    "    dt.datetime.strptime(trip_start, \"%Y-%m-%d\") - dt.timedelta(365)\n",
    ")[:10]\n",
    "trip_early_end = str(dt.datetime.strptime(trip_end, \"%Y-%m-%d\") - dt.timedelta(365))[\n",
    "    :10\n",
    "]\n",
    "plot_data = calc_temps(trip_start, trip_end)\n",
    "plot_data_early = calc_temps(trip_early_start, trip_early_end)\n",
    "print(plot_data, plot_data_early)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results from your previous query as a bar chart. Use \"Trip Avg Temp\" as your Title. Use the average temperature for the y value\n",
    "#### Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = plot_data_early[0][0] - plot_data_early[0][2]\n",
    "plt.title(\"Trip Avg Temp\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.grid(axis=\"x\")\n",
    "plt.bar(x=\" \", height=plot_data_early[0][1], alpha=0.6)\n",
    "plt.errorbar(x=0, y=plot_data_early[0][1], yerr=error, ecolor=\"black\")\n",
    "plt.savefig(\"plot_trip.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data2 = []\n",
    "df_data2_sums = []\n",
    "sel = [\n",
    "    Measurement.id,\n",
    "    Measurement.prcp,\n",
    "    Station.id,\n",
    "    Station.station,\n",
    "    Station.name,\n",
    "    Station.latitude,\n",
    "    Station.longitude,\n",
    "    Station.elevation,\n",
    "]\n",
    "q = (\n",
    "    session.query(*sel, func.sum(Measurement.prcp).label(\"Total_Prcp\"))\n",
    "    .filter(Measurement.station == Station.station)\n",
    "    .filter(Measurement.date)\n",
    "    .group_by(\"station\")\n",
    "    .all()\n",
    ")\n",
    "for record in q:\n",
    "    df_data2.append(record)\n",
    "df_prcp_sums = pd.DataFrame(df_data2)\n",
    "df_prcp_sums.columns = [\n",
    "    \"id\",\n",
    "    \"prcp\",\n",
    "    \"fakeid\",\n",
    "    \"station\",\n",
    "    \"name\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"elevation\",\n",
    "    \"total_prcp\",\n",
    "]\n",
    "df_prcp_sums = df_prcp_sums.drop([\"fakeid\", \"prcp\"], axis=1)\n",
    "df_prcp_sums = df_prcp_sums.set_index(\"id\").sort_values(\"total_prcp\", ascending=False)\n",
    "df_prcp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62.0, 69.15384615384616, 77.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62.0, 69.15384615384616, 77.0),\n",
       " (60.0, 69.39622641509433, 77.0),\n",
       " (62.0, 68.9090909090909, 77.0),\n",
       " (58.0, 70.0, 76.0),\n",
       " (56.0, 67.96428571428571, 76.0),\n",
       " (61.0, 68.96491228070175, 76.0),\n",
       " (57.0, 68.54385964912281, 76.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmin</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>62.0</td>\n",
       "      <td>69.153846</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>60.0</td>\n",
       "      <td>69.396226</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>62.0</td>\n",
       "      <td>68.909091</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>58.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>56.0</td>\n",
       "      <td>67.964286</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmin       tavg  tmax\n",
       "date                             \n",
       "2018-01-01  62.0  69.153846  77.0\n",
       "2018-01-02  60.0  69.396226  77.0\n",
       "2018-01-03  62.0  68.909091  77.0\n",
       "2018-01-04  58.0  70.000000  76.0\n",
       "2018-01-05  56.0  67.964286  76.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "hw10_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
